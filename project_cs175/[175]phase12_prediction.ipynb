{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b86fb077df11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpm_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import cpm_utils, utils\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import importlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import FLAGS\n",
    "import Detector as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\triangle\\deeplearning\\175project\\hand_pose\\test_img\n"
     ]
    }
   ],
   "source": [
    "FLAGS.DEMO_TYPE = 'D:\\\\triangle\\\\deeplearning\\\\175project\\\\hand_pose\\\\test_img' \n",
    "print(FLAGS.DEMO_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm_model = importlib.import_module('models.nets.' + FLAGS.network_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu_id)\n",
    "\n",
    "\"\"\" Build network graph\n",
    "\"\"\"\n",
    "model = cpm_model.CPM_Model(input_size=FLAGS.input_size,\n",
    "                            heatmap_size=FLAGS.heatmap_size,\n",
    "                            stages=FLAGS.cpm_stages,\n",
    "                            joints=FLAGS.num_of_joints,\n",
    "                            img_type=FLAGS.color_channel,\n",
    "                            is_training=False)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size= 256 \n",
      "heatmap_size= 32 \n",
      "stages= 3 \n",
      "joints= 21 \n",
      "img_type= RGB \n",
      "is_training= False\n"
     ]
    }
   ],
   "source": [
    "print(\"input_size=\" ,FLAGS.input_size,\n",
    "                            \"\\nheatmap_size=\", FLAGS.heatmap_size,\n",
    "                            \"\\nstages=\", FLAGS.cpm_stages,\n",
    "                            \"\\njoints=\", FLAGS.num_of_joints,\n",
    "                            \"\\nimg_type=\", FLAGS.color_channel,\n",
    "                            \"\\nis_training=\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This is to set up some GPU options for the tensorflow model\n",
    "\"\"\"\n",
    "output_node = tf.get_default_graph().get_tensor_by_name(name=FLAGS.output_node_names)\n",
    "\n",
    "device_count = {'GPU': 1} if FLAGS.use_gpu else {'GPU': 0}\n",
    "sess_config = tf.ConfigProto(device_count=device_count)\n",
    "sess_config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess_config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_and_draw_hand(full_img, stage_heatmap_np, crop_img, original_info):\n",
    "    global_joint = np.zeros((FLAGS.num_of_joints, 2))\n",
    "    local_joint = np.zeros((FLAGS.num_of_joints, 2))\n",
    "\n",
    "    mean_response_val = 0.0\n",
    "\n",
    "    # Plot joint colors\n",
    "    for joint_num in range(FLAGS.num_of_joints):\n",
    "        #this takes the last heatmap\n",
    "        tmp_heatmap = stage_heatmap_np[:, :, joint_num]\n",
    "\n",
    "        #find which position have the largest possibiility to be this joint, and rewrite in form of length-2 list\n",
    "        joint_coord = np.unravel_index(np.argmax(tmp_heatmap),\n",
    "                                       (FLAGS.input_size, FLAGS.input_size))\n",
    "        #for each joint, add its highest(also the taken) score to total response\n",
    "        mean_response_val += tmp_heatmap[joint_coord[0], joint_coord[1]]\n",
    "        joint_coord = np.array(joint_coord).astype(np.float32)\n",
    "\n",
    "        local_joint[joint_num, :] = joint_coord\n",
    "\n",
    "        # Resize back\n",
    "        joint_coord *= original_info[2] / FLAGS.input_size\n",
    "\n",
    "        joint_coord[0] += original_info[0]\n",
    "        joint_coord[1] += original_info[1]\n",
    "        global_joint[joint_num, :] = joint_coord\n",
    "\n",
    "\n",
    "    #if we feel like it fails, then we will just place a default hand on the screen\n",
    "    if mean_response_val >= 1:\n",
    "        draw_hand(full_img, global_joint)\n",
    "        draw_hand(crop_img, local_joint)\n",
    "        cv2.putText(full_img, 'Response: {:<.3f}'.format(mean_response_val),\n",
    "                    org=(original_info[1], original_info[0]), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 0, 0))\n",
    "    \n",
    "    #we put response on crop image, and original image\n",
    "    cv2.putText(crop_img, 'Response: {:<.3f}'.format(mean_response_val),\n",
    "                org=(20, 20), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw hand points and circles on the canvas\n",
    "def draw_hand(canvas, joint): \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(len(joint)):\n",
    "        cv2.circle(canvas, (int(joint[i][1]),int(joint[i][0])), 4, FLAGS.joint_color_code[i], thickness=-1)\n",
    "    for edge in FLAGS.limbs:\n",
    "        u,v = edge\n",
    "        cv2.line(canvas,(int(joint[u][1]),int(joint[u][0])),(int(joint[v][1]),int(joint[v][0])),FLAGS.joint_color_code[v],3)\n",
    "def normalize_and_centralize_img(img):\n",
    "    if FLAGS.normalize_img:\n",
    "        norm_img = img / 256.0 - 0.5\n",
    "        #expand_dims expand the dimension ,axis = 0 means new_img[0] is the original\n",
    "        #[[1,2],[3,4]] ==axis0==> [[[1,2],[3,4]]]\n",
    "        #[[1,2],[3,4]] ==axis1==> [[[1,2]],[[3,4]]]\n",
    "        #[[1,2],[3,4]] ==axis2==> [[[1],[2]],[[3],[4]]]\n",
    "        norm_img = np.expand_dims(norm_img, axis=0)\n",
    "    else:\n",
    "        norm_img = img - 128.0\n",
    "        norm_img = np.expand_dims(norm_img, axis=0)\n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(padding, position=None):\n",
    "    test_img = []\n",
    "    img_name = []\n",
    "    if FLAGS.DEMO_TYPE.endswith(('png', 'jpg')):\n",
    "        test_img.append(cv2.imread(FLAGS.DEMO_TYPE))\n",
    "        img_name.append(FLAGS.DEMO_TYPE)\n",
    "    else:\n",
    "        file_list = os.listdir(FLAGS.DEMO_TYPE)\n",
    "        if position!= None:\n",
    "            file_list = file_list[position[0]:position[1]]\n",
    "\n",
    "        for img in file_list:\n",
    "            test_img.append(cv2.imread(os.path.join(FLAGS.DEMO_TYPE, img)))\n",
    "            img_name.append(os.path.join(FLAGS.DEMO_TYPE, img))\n",
    "    tt = time.time()\n",
    "    boxes = dt.bounding_box_from_folder(FLAGS.DEMO_TYPE, padding, position)\n",
    "    print(\"Phase 1: \", time.time() - tt)\n",
    "\n",
    "    for index, b_box in enumerate(boxes):\n",
    "        t0 = time.time()\n",
    "        bb_img = []\n",
    "        bb_img_resize = []\n",
    "        original_info = [] #so that can be recovered from original size and position, with order: ymin, xmin, original length/width\n",
    "        if b_box != []: \n",
    "            bb_box = b_box[0]\n",
    "            bb_img.append(np.copy(test_img[index][bb_box[1]:bb_box[3],bb_box[0]:bb_box[2],:]))\n",
    "            original_info.append([bb_box[1], bb_box[0], bb_img[0].shape[0]])\n",
    "            if len(b_box) > 1: \n",
    "                bb_box = b_box[1]\n",
    "                bb_img.append(np.copy(test_img[index][bb_box[1]:bb_box[3],bb_box[0]:bb_box[2],:])) \n",
    "                original_info.append([bb_box[1], bb_box[0], bb_img[1].shape[0]])\n",
    "\n",
    "        # this is useless, because it already forces to input size\n",
    "        for i in range(len(bb_img)):\n",
    "            bb_img[i] = cv2.resize(bb_img[i], (FLAGS.input_size, FLAGS.input_size))\n",
    "            bb_img_resize.append(normalize_and_centralize_img(bb_img[i]))\n",
    "\n",
    "            t1 = time.time()\n",
    "\n",
    "            #current_heatmap is the output after going through the last layer\n",
    "            #input_images is a placeholder matrix for iiamge size\n",
    "            # FIXME: I don't know what exactly does this sess run with? the two arguments?\n",
    "            #predict_heatmap.shape = (1,32,32,22) \n",
    "            #stage_heatmap_np.shape = (1,32,32,22), it seems like, for stage_heatmap, each of the 1*32*32 is something same, a 22 length-array\n",
    "            predict_heatmap, stage_heatmap_np = sess.run([model.current_heatmap,\n",
    "                                                          output_node,\n",
    "                                                          ],\n",
    "                                                         feed_dict={model.input_images: bb_img_resize[i]}\n",
    "                                                         )\n",
    "            #frame per second\n",
    "            print('fps: %.2f' % (1 / (time.time() - t1)))\n",
    "\n",
    "            correct_and_draw_hand(test_img[index],\n",
    "                                  cv2.resize(stage_heatmap_np[0], (FLAGS.input_size, FLAGS.input_size)),\n",
    "                                  bb_img[i], original_info[i])\n",
    "\n",
    "        # Show visualized image\n",
    "        '''if len(bb_img) > 0:\n",
    "            cv2.imshow(img_name[index] + '-1', bb_img[0].astype(np.uint8))\n",
    "            if len(bb_img) > 1:\n",
    "                cv2.imshow(img_name[index] + '-2', bb_img[1].astype(np.uint8))\n",
    "            #cv2.waitKey(0)\n",
    "        else:\n",
    "            null_img = np.zeros((FLAGS.input_size, FLAGS.input_size, 3))\n",
    "            cv2.imshow(img_name[index] + ': not found', null_img.astype(np.uint8))\n",
    "            #cv2.waitKey(0)'''\n",
    "        tmp_img = cv2.resize(test_img[index], (1280, 720))      \n",
    "        cv2.imshow(img_name[index] + '-0', tmp_img.astype(np.uint8))\n",
    "        print(\"Total time for\" + str(index) + \": \" +str(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff59d19642d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FIXME: should merge together, so that lib will not be imported twice, and that speed will be accelerated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# additionally, there seems to be a shift problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model_path_suffix = os.path.join(FLAGS.network_def,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# FIXME: should merge together, so that lib will not be imported twice, and that speed will be accelerated\n",
    "# additionally, there seems to be a shift problem\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "\n",
    "    model_path_suffix = os.path.join(FLAGS.network_def,\n",
    "                                     'input_{}_output_{}'.format(FLAGS.input_size, FLAGS.heatmap_size),\n",
    "                                     'joints_{}'.format(FLAGS.num_of_joints),\n",
    "                                     'stages_{}'.format(FLAGS.cpm_stages),\n",
    "                                     'init_{}_rate_{}_step_{}'.format(FLAGS.init_lr, FLAGS.lr_decay_rate,\n",
    "                                                                      FLAGS.lr_decay_step)\n",
    "                                     )\n",
    "    model_save_dir = os.path.join('models',\n",
    "                                  'weights',\n",
    "                                  model_path_suffix)\n",
    "    print('Load model from [{}]'.format(os.path.join(model_save_dir, FLAGS.model_path)))\n",
    "\n",
    "    # if the model is a pkl file, then load it, else just restore the pretrained cpm_hand by default\n",
    "    # by here we can see the loading weight structure\n",
    "    if FLAGS.model_path.endswith('pkl'):\n",
    "        model.load_weights_from_file(FLAGS.model_path, sess, False)\n",
    "    else:\n",
    "        saver.restore(sess, 'models/weights/cpm_hand')\n",
    "\n",
    "    # Check weights, this seems to be the part that print out weights\n",
    "    for variable in tf.global_variables():\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            #this is becuase each layer variable has ':0' inside its name\n",
    "            var = tf.get_variable(variable.name.split(':0')[0])\n",
    "            #print(variable.name, np.mean(sess.run(var)))\n",
    "\n",
    "        \n",
    "    t1 = time.time()\n",
    "    print(\"Prediction process starts...\")\n",
    "    #we assume they are all images, either folder or single image file\n",
    "    #if FLAGS.DEMO_TYPE.endswith(('png', 'jpg')): \n",
    "    predict_image(30, None)\n",
    "    #else:\n",
    "        #for img in (os.listdir(FLAGS.DEMO_TYPE))[1002:1007]:\n",
    "            #predict_one_image(img, 30)\n",
    "    print(time.time() - t1)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 22) (1, 32, 32, 22)\n"
     ]
    }
   ],
   "source": [
    "#store_predict_heatmap = predict_heatmap\n",
    "#store_stage_heatmap_np = stage_heatmap_np\n",
    "print(store_predict_heatmap.shape, store_stage_heatmap_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to show what is inside these two\n",
    "\n",
    "tmp = np.zeros((32, 32))\n",
    "tmp2 = np.zeros((32, 32))\n",
    "enumerater = np.array(range(22))[21:]\n",
    "\n",
    "for i in enumerater:\n",
    "    tmp += 43000 * store_predict_heatmap[0,:,:,i]\n",
    "    tmp2 += 43000 * store_stage_heatmap_np[0,:,:,i]\n",
    "cv2.imshow('', tmp.astype(np.uint8))\n",
    "cv2.imshow('2', tmp2.astype(np.uint8))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
